PyTorch WMT17 Transformer Machine Translation
"""""""""""""""""""""""""""""""""""""""""""""

Transformer implementation `Attention Is All You need <https://arxiv.org/abs/1706.03762>`_

:Task: :ref:`Task 4b <mlbench-docs:benchmark-task-4b>`
:Framework: PyTorch
:Communication Backend: Open MPI, NCCL and GLOO (PyTorch `torch.distributed`)
:Distribution Algorithm: All-Reduce
:Model: Transformer
:Dataset: WMT17
:GPU: Yes
:Seed: 42
:Image Location: mlbench/pytorch-wmt17-transformer-all-reduce:latest

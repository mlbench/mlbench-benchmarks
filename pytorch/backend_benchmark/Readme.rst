PyTorch Communication backend Benchmarking
""""""""""""""""""""""""""""""""""""""""""

Benchmarking of communication backends in PyTorch

:Task: :ref:`Task 0a <mlbench-docs:benchmark-task-0a>`
:Framework: PyTorch
:Communication Backend: Open MPI, GLOO, NCCL (PyTorch `torch.distributed`)
:Distribution Algorithm: All-Reduce
:GPU: Yes
:Seed: 42
:Image Location: mlbench/pytorch-backend-benchmark:latest